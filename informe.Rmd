---
title: "Trabajo 1 - Muestreo y Planificación de Encuestas I"
author: "Matias Bajac - Lucas Pescetto - Andres Vidal"
date: '2023-04-10'
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.show = "all")

rm(list = ls())

library(tidyverse)
library(haven)
library(survey)
library(sampling)
library(ggplot2)
library(gridExtra)

set.seed(0)
```

# Introducción

Partimos de la base de datos del censo de hogares de 2011 en Rio Branco
para estudiar los diseños **Simple sin reposición (SI)**, **Simple con reposición (SIR)** y **Bernoulli (BER)**.
Nos interesa estimar el total poblacional de dos variables calculadas a partir de la base de datos en cuestión:

- `nbi`: vale 0 si el hogar tiene 3 o menos necesidades básicas insatisfechas (NBI) y 1 si tiene 4 o más.
- `xo`: vale 0 si el hogar tiene algún dispositivo, y 1 en caso de no contar con ninguno.

Esto es, estaremos estimando la cantidad de hogares con 4 o más NBI y la cantidad de hogares sin computadoras XO.
Además del cálculo de las variables `nbi` y `xo` a partir de la base de datos, esto requirió remover observaciones duplicadas,
puesto que la base está a nivel de personas e interesa calcular los totales a nivel de hogares.

```{r data_processing, include=FALSE}
is_nbi_missing <- function(x) x %in% c(8, 9)
is_nbi_var <- function() starts_with("NBI_")
mutate_nbi <- function(x) zap_labels(x) %>% if_else(is_nbi_missing(.), 0, .)
select_nbi <- function(x) select(x, is_nbi_var(), -NBI_CANTIDAD)
has_xo <- function(x) if_else(x$HOGCE09 == 0, 1, 0)
has_nbi <- function(x) if_else(x$NBI_TOTAL >= 4, 1, 0)

load("datos.RData")
data <- rio_branco %>%
  mutate(across(is_nbi_var(), ~ mutate_nbi(.))) %>%
  mutate(NBI_TOTAL = rowSums(select_nbi(.)), XO = has_xo(.)) %>%
  mutate(NBI = has_nbi(.), ID = paste(ID_VIVIENDA, HOGID)) %>%
  filter(!duplicated(ID)) %>%
  select(nbi = NBI, xo = XO)

t_nbi <- sum(data$nbi)
t_xo <- sum(data$xo)

N <- nrow(data)
```


# Distribución empírica del estimador

En esta parte presentamos el marco de trabajo del análisis.
Definimos funciones auxiliares para automatizar el análisis y estandarizar y simplificar la presentación de los resultados.
El objetivo es abstraer los procedimientos a ser realizaos de los tamaños de muestra y de los diseños de muestreo.
Para esto, utilizamos el paquete `survey`.

## Funciones Auxiliares

Definimos funciones auxiliares para facilitar el resto del análisis:

- `estimate_total` recibe un nombre de variable y un diseño de muestreo para estimar un total poblacional. Envuelve la función `svytotal` del paquete `survey` para facilitar su uso.
- `estimate_totals` recibe un nombre de variable y una lista de diseños de muestreo y estima el total poblacional para cada diseño. Se utiliza especialmente para automatizar la aplicación sobre varios tamaños de muestra.
- `show_results` recibe un nombre de variable y una lista de resultados para mostrarlos de forma estándar.
- `confint_norm` recibe un estimador (resultado de `svytotal`) y calcula el intervalo de confianza al 95% asumiendo distribución normal.

```{r auxiliar}
estimate_total <- function(var, design) {
  svytotal(as.formula(paste0("~", var)), design, deff = TRUE)
}

estimate_totals <- function(var, design_list) {
  lapply(design_list, function(design) estimate_total(var, design))
}

show_results <- function(var, named_result_list) {
  t(as.data.frame(t(named_result_list), row.names = var))
}

confint_norm <- function(t_estimate) {
  t <- coef(t_estimate)
  se <- SE(t_estimate)

  ci <- cbind(
    t - qnorm(0.975) * se,
    t + qnorm(0.975) * se
  )
  colnames(ci) <- c("2.5%", "97.5%")
  ci
}
```

## Muestreo del estimador

Obtenemos 1000 muestras y calculamos el estimador del total poblacional para cada una de ellas.
La función `sample_t_estimate` implementa este procedimiento genéricamente, recibiendo como parámetros:

- `var` La variable que se desea estimar
- `sample_size` el tamaño de las muestras que se deben tomar
- `get_sample` una función que dado valor `n` devuelve una muestra de tamaño `n`
- `get_design` una función que dada una muestra devuelve un objeto de diseño de muestreo generado con `svydesign`

```{r estimate_dist_sample}
sample_t_estimate <- function(var, sample_size, get_sample, get_design) {
  n_simulations <- 1000

  replicate(n_simulations, {
    sample <- get_sample(sample_size)
    design <- get_design(sample)
    coef(estimate_total(var, design))
  })
}
```

Utiliza `estimate_total` para estimar el total poblacional para la variable indicada.
Además, definimos la función `empirical_distribution_sir` (cuyo código no está expuesto en el informe)
que toma los mismos parámetros, utiliza `sample_t_estimate`, grafica la distribución empírica
y retorna resúmenes de la distribución empírica del estimador, como la media, la varianza y los intervalos de confianza empíricos al 95% de confianza,
para cada tamaño de muestra.

```{r estimate_dist_plots, include=FALSE}
empirical_distribution_sir <-
  function(var, sample_sizes, get_sample, get_design) {
    result <- lapply(sample_sizes, function(sample_size) {
      pivot <- estimate_total(var, get_design(get_sample(sample_size)))



      # Simular
      t <- data.frame(
        estimate = sample_t_estimate(var, sample_size, get_sample, get_design)
      )

      # Regla de Scott para el ancho de los bins
      binwidth <- 3.5 * sd(t$estimate) / (sample_size^(1 / 3))

      t_actual <- get(paste0("t_", var))

      # Graficar Histograma + Curva de densidad
      plot <- ggplot(t, aes(x = estimate)) +
        geom_histogram(
          aes(y = after_stat(density)),
          binwidth = binwidth,
          color = "black",
          fill = "white"
        ) +
        geom_density(
          alpha = 0.2,
          fill = "blue",
          color = "blue"
        ) +
        geom_vline(
          aes(xintercept = mean(estimate)),
          color = "blue",
          linewidth = 0.7
        ) +
        geom_vline(
          aes(xintercept = t_actual),
          color = "red",
          linewidth = 0.7
        ) +
        geom_area(
          stat = "function",
          fun = dnorm,
          args = list(mean = t_actual, sd = SE(pivot)),
          alpha = 0.2,
          fill = "red",
          color = "red"
        ) +
        labs(
          x = var,
          y = "Density",
          title = paste0("Función de Densidad Empírica - n = ", sample_size)
        ) +
        theme_classic()


      list(
        plot = plot,
        q95 = quantile(t$estimate, c(0.025, 0.975)),
        mean = mean(t$estimate),
        var = sd(t$estimate)
      )
    })

    plots <- lapply(result, function(r) r$plot)
    quantiles <- lapply(result, function(r) r$q95)
    means <- lapply(result, function(r) r$mean)
    standard_errors <- lapply(result, function(r) r$var)
    names(quantiles) <- names(means) <- names(standard_errors) <- sample_sizes


    grid.arrange(grobs = plots, padding = 5)

    list(
      quantiles = as.data.frame(t(as.data.frame(quantiles))),
      means = as.data.frame(t(as.data.frame(means))),
      standard_errors = as.data.frame(t(as.data.frame(standard_errors)))
    )
  }
```

# Diseño de muestreo SIR

En esta parte analizamos el diseño **Simple con Reposición (SIR)**.
En primera instancia, definimos los artefactos necesarios para utilizar nuestro marco de trabajo.
Luego, estimamos la distribución empírica del estimador del total poblacional para `nbi` y para `xo`
y comparamos sus características con el parámetro poblacional y con el estimador teórico de la varianza del estimador poblacional.

## Definición del diseño

Definimos la función `get_sir_design` que recibe una muestra y genera un objeto de diseño de muestreo
con `svydesign` del paquete `survey` de la siguiente manera:

```{r sir_design}
get_sir_design <- function(sample) {
  svydesign(
    ids = ~1,
    data = sample,
    probs = nrow(sample) / N
  )
}
```

En este caso, la estrategia de muestreo es diseño SIR con estimador $t_{pwr}$.
Entonces, la probabilidad de inclusión de cada unidad es la misma para todas las unidades y está definida como
$n \ N$, dónde $n$ es el tamaño de la muestra y $N$ es el tamaño de la población.

## Algoritmo de selección

Definimos la función `get_sir_sample` que recibe el tamaño de la muestra y devuelve una muestra de tamaño `n` utilizando el método SIR.
Específicamente, esto se implementa utilizando la función `srswr` del paquete `sampling`.

```{r sir_sampling}
get_sir_sample <- function(sample_size) {
  index <- srswr(sample_size, N)
  getdata(data, index)
}
```

## Obtener muestras finales

Utilizamos la función `get_sir_sample` para obtener muestras de tamaño 150, 600 y 1000
y almacenarlas en la lista `sir_samples`.

```{r sir_samples}
sample_sizes <- c(150, 600, 1000)
sir_samples <- lapply(sample_sizes, get_sir_sample)
names(sir_samples) <- sample_sizes
```

## Obtener objetos de diseño finales

Utilizamos la función `get_sir_design` para obtener los objetos de diseño de muestreo finales
para cada muestra. Almacenamos estos objetos en la lista `sir_designs`.

```{r sir_designs}
sir_designs <- lapply(sir_samples, get_sir_design)
```

## Análisis de NBI

En esta parte analizamos los resultados obtenidos para la variable `nbi`.
Interesa estimar el total de hogares con 4 o más NBI.

### Distribución empírica del estimador para el total de NBI

Utilizamos la función `empirical_distribution_sir` para obtener y visualizar la distribución empírica del estimador.
Esta función utiliza internamente a la función `sample_t_estimate` presentada anteriormente.
Para esto es necesario pasar las funciones  `get_sir_sample` y `get_sir_design` definidas recién como parámetros.

Como resultado, obtenemos resúmenes de la distibución empírica y los en la variable `t_nbi_dist`.
Además visualizamos la distribución empírica para cada tamaño de muestra mediante histogramas y la función de densidad empírica.
Mostramos el valor real del total poblacional de `nbi` como una línea vertical roja y el promedio muestral como una línea vertical azul.
La función de densidad empírica se muestra como un área azul y la función de densidad teórica (Normal con media en el parámetro poblacional y la varianza teórica del estimador) y como un área roja.

```{r sir_nbi_estimate_dist, results='show'}
t_nbi_dist <- empirical_distribution_sir(
  "nbi",
  sample_sizes,
  get_sir_sample,
  get_sir_design
)
```

A seguir podemos observar las estimaciones puntuales para el total poblacional, los promedios empíricos
y el sesgo de cada uno (la diferencia con el parámetro real) para cada tamaño de muestra.
Observamos bajo sesgo de la distribución empírica, lo cual puede visualizarse en los gráficos arriba.
El estimado, sin embargo, presenta un sesgo de aproximadamente 20 unidades, con una leve reducción a medida que aumenta el tamaño de la muestra.

```{r sir_nbi_estimate, echo=FALSE}
t_nbi_estimates <- estimate_totals("nbi", sir_designs)
a <- show_results("t_estimate", t_nbi_estimates)
b <- show_results("t_dist_mean", t_nbi_dist$means)
c <- as.data.frame(
  cbind(
    a,
    bias = abs(mapply("-", a, t_nbi)),
    b,
    bias = abs(mapply("-", b, t_nbi)),
    difference = abs(mapply("-", a, b))
  ),
)

c
```

Abajo reportamos las estimaciones del desvío estándar teórico del estimador y su varianza empírica, respectivamente, para cada tamaño de muestra.
Observamos reducción en ambas estimaciones del desvío estándar al aumentar el tamaño de muestra.
Por otro lado, al observar la diferencia entre ambos estimadores, se observa  una reducción del 71% al aumentar el tamaño de la muestra de 150 a 600
y un aumento del 37% al aumentar el tamaño de muestra de 600 a 1000.
Esto quiere decir que la varianza resultó mejor estimada por la fórmula teórica para el tamaño de muestra de 600.
Sin embargo, la diferencia para ambos tamaños de muestra (600 y 1000) es pequeña.

El bajo error al estimar la varianza del estimador puede apreciarse también en los gráficos,
al observar la semejanza entre la curva roja (densidad teórica asintótica) y la curva azul (densidad empírica).

```{r sir_nbi_estimate_var, echo=FALSE}
a <- show_results("Var(t_nbi)", lapply(t_nbi_estimates, SE))
b <- show_results("Var(t_dist)", t_nbi_dist$standard_errors)
c <- as.data.frame(cbind(a, b, difference = abs(mapply("-", a, b))))
c
```

### Efecto diseño del estimador para el total de NBI

A seguir presentamos los valores del efecto diseño para el estimador del total poblacional en cada tamaño de muestra. 
El efecto diseño resultó mayor que 1 para todos los casos, por la estrategia de muestreo (SIR con estimador $t_{pwr}$)
causa pérdida de eficiencia en varianza respecto al diseño SI con estimador HT.

Observamos también que a mayores tamaños de muestra aumenta el efecto diseño,
por lo que concluimos que esta estrategia pierde eficiencia al aumentar tamaño de muestra.

```{r sir_nbi_estimate_deff, echo=FALSE}
t_nbi_estimates_deff <- lapply(t_nbi_estimates, deff)
show_results("deff", t_nbi_estimates_deff)
```

### Intervalos de confianza para el total de NBI

Abajo reportamos los intervalos de confianza **empíricos** al 95% de confianza para el total de la variable `nbi` en cada tamaño de muestra.
En la tercera columna incluímos el rango de cada intervalo, como medida de su precisión.

Observamos que, además de que todos los intervalos incluyen al total real de la variable `nbi` (538 hogares),
la precisión de los intervalos aumentan con el tamaño de muestra.
Al aumentar el tamaño de muestra de 150 a 600 observamos una reducción del 48% en el rango y al aumentar el tamaño de muestra de 600 a 1000 observamos una reducción del 23%.


```{r sir_nbi_estimate_quantiles, echo=FALSE}
t_nbi_dist$quantiles$range <- t_nbi_dist$quantiles$"97.5%" - t_nbi_dist$quantiles$"2.5%"
t_nbi_dist$quantiles
```

Abajo reportamos los intervalos de confianza al 95% asumiendo que el estimador se distribuye con normalidad.
En este caso, tambien observamos una reducción del 48% en el rango al aumentar el tamaño de muestra de 150 a 600 y una reducción del 23% al aumentar de 600 a 1000 elementos.
Por lo tanto, concluimos que en el caso normal el intervalo de confianza es más preciso a medida que aumenta el tamaño de muestra. 

```{r sir_nbi_estimate_confint, echo=FALSE}
t_nbi_confint <- as.data.frame(do.call(rbind, lapply(t_nbi_estimates, confint_norm)))
t_nbi_confint$range <- t_nbi_confint$"97.5%" - t_nbi_confint$"2.5%"
rownames(t_nbi_confint) <- sample_sizes
t_nbi_confint
```

Al comparar los intervalos de confianza empíricos y los intervalos de confianza asumiendo normalidad,
observamos su similaridad en términos de rango y posición, lo que implica que también coincidan respecto a su variación con el tamaño de muestra.
Destacamos, sin embargo, que los intervalos al considerar tamaño de muestra de 600 o 1000 son más cercanos que cuando el tamaño de muestras es 150.
Esto es razonable, puesto que la normalidad del estimador del total poblacional es asintótica, por lo que será más evidente a medida que crece el tamaño de muestra.

## Análisis de XO

En esta parte se presenta el mismo procedimiento realizado para la variable `nbi`, pero considerando a la variable `xo` como característica de interés.
Interesa estimar el total de hogares con al menos un dispositivo XO.

### Distribución empírica del estimador para el total de XO

A seguir presentamos los gráficos de la distribución empírica del estimador del total de `xo`.
Destacamos la similiridad entre la distribución empírica (área azul) y la distribución teórica (área roja).

```{r sir_xo_estimate_dist, echo=FALSE, results='show'}
t_xo_dist <- empirical_distribution_sir(
  "xo",
  sample_sizes,
  get_sir_sample,
  get_sir_design
)
```


Respecto a las estimaciones puntuales para el total de `xo`, ov

```{r sir_xo_estimate, echo=FALSE}
t_xo_estimates <- estimate_totals("xo", sir_designs)
a <- show_results("t_estimate", t_xo_estimates)
b <- show_results("t_dist_mean", t_xo_dist$means)
c <- as.data.frame(
  cbind(
    a,
    bias = abs(mapply("-", a, t_xo)),
    b,
    bias = abs(mapply("-", b, t_xo)),
    difference = abs(mapply("-", a, b))
  )
)
c
```

```{r sir_xo_estimate_var, echo=FALSE}
a <- show_results("Var(t_xo)", lapply(t_xo_estimates, SE))
b <- show_results("Var(t_dist)", t_xo_dist$standard_errors)
c <- as.data.frame(cbind(a, b, difference = abs(mapply("-", a, b))))
c
```

```{r sir_xo_estimate_deff, echo=FALSE}
t_xo_estimates_deff <- lapply(t_xo_estimates, deff)
show_results("deff", t_xo_estimates_deff)
```

```{r sir_xo_estimate_confint, echo=FALSE}
t_xo_confint <- as.data.frame(do.call(rbind, lapply(t_xo_estimates, confint_norm)))
t_xo_confint$range <- t_xo_confint$"97.5%" - t_xo_confint$"2.5%"
rownames(t_xo_confint) <- sample_sizes
t_xo_confint
```